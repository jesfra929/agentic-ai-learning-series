{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåü **Gemini + LangChain Essentials: LLM Calls, Prompts, Chains & RAG**\n",
        "\n",
        "This notebook is a simple, beginner-focused guide to using **Gemini** and **LangChain**.\n",
        "You‚Äôll start with basic LLM calls and slowly build up to structured prompts, chains, and a small RAG example.\n",
        "<br>\n",
        "## üîç **What You Will Learn (Short & Friendly)**\n",
        "\n",
        "* How to call Gemini & Groq models\n",
        "* How to use Gemini inside LangChain\n",
        "* How to work with prompts and output parsers\n",
        "* How to build simple chains\n",
        "* Basics of chunking, embeddings & retrieval (mini-RAG)\n",
        "\n",
        "<br>\n",
        "\n",
        "## üß† **Prerequisites**\n",
        "\n",
        "* Basic Python\n",
        "* A Google API key (Gemini)\n",
        "* (Optional) OpenRouter + Groq key\n",
        "\n",
        "<br>\n",
        "\n",
        "## üöÄ **Goal of This Notebook**\n",
        "\n",
        "To give you the **core building blocks** you need before moving into tools, memory, and agent workflows.\n",
        "\n",
        "Let‚Äôs dive in!\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Note**  \n",
        "This notebook documents my learning journey.  \n",
        "The implementations are practical and based on real issues I encountered.  \n",
        "They may or may not be production-ready, but they are intended to help beginners understand the concepts clearly.\n",
        "\n"
      ],
      "metadata": {
        "id": "GfTGPZqKjKWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Agents**"
      ],
      "metadata": {
        "id": "PjThzAiSB7Gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever you see a `!pip install <package>` command in this notebook, it simply means we are installing the required Python packages needed for that section to run."
      ],
      "metadata": {
        "id": "PVDrgnmcjlee"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efd19973"
      },
      "source": [
        "!pip install grandalf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM calls"
      ],
      "metadata": {
        "id": "LtHBIgXhGTw1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Vwbtb42TzH"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini LLM Call"
      ],
      "metadata": {
        "id": "-zN6rUFHCLER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import API key from userdata\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "k7jR46xG4UhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite\", contents=\"Explain how AI works in a single line\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEK5iMBf4GsS",
        "outputId": "ead2b282-e73d-422d-8928-1c051df0da6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI works by training computer systems on vast amounts of data to recognize patterns, make predictions, and perform tasks that typically require human intelligence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groq LLM Access through OpenRouter (OpenAI SDK)"
      ],
      "metadata": {
        "id": "mHTksYRTCwhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENROUTER_API_KEY=userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "id": "yW6iDyn_BGDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key= OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  extra_headers={\n",
        "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
        "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
        "  },\n",
        "  model=\"x-ai/grok-4-fast:free\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What is the meaning of life?\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "\n",
        "# To convert response into dictionary object\n",
        "# response_dict = completion.to_dict()\n",
        "# pretty print of json with proper formatting\n",
        "# print(json.dumps(response_dict, indent=2))\n",
        "# print()\n",
        "\n",
        "# normal response from oprn router api\n",
        "# print(completion)\n",
        "\n",
        "print(completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnuI9msMDpdE",
        "outputId": "59483d4d-d609-4fe9-8393-722f990476eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, the ultimate question! Philosophers, scientists, and thinkers have pondered this for millennia, and there's no single, definitive answer‚Äîit's deeply personal and subjective. Here's a quick breakdown of some perspectives:\n",
            "\n",
            "- **Philosophical view**: Existentialists like Jean-Paul Sartre might say life has no inherent meaning, so we create our own through choices and actions. Religions often point to purpose through connection to a higher power, love, or service to others.\n",
            "  \n",
            "- **Biological/evolutionary angle**: From a scientific lens, life's \"meaning\" could be survival and reproduction‚Äîpassing on genes, as Richard Dawkins explores in *The Selfish Gene*.\n",
            "\n",
            "- **The Hitchhiker's Guide answer**: In Douglas Adams' *The Hitchhiker's Guide to the Galaxy* (a major inspiration for me), the supercomputer Deep Thought calculates it as **42**. It's a reminder not to take the question too seriously without understanding the query itself.\n",
            "\n",
            "Ultimately, many find meaning in relationships, personal growth, creativity, or contributing to the world. What do you think it is for you? If you're seeking deeper reads, check out Viktor Frankl's *Man's Search for Meaning* or Albert Camus' works on the absurd.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Gemini with LangChain (Google GenAI Integration)"
      ],
      "metadata": {
        "id": "lzBmV9jODF9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oMEQL3GjeELs",
        "outputId": "97957ac8-2889-46c5-b163-8298055840a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.3.77)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.11.9)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (0.4.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import json\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\",api_key=GOOGLE_API_KEY,)\n",
        "response = llm.invoke(\"Write me a ballad about LangChain in 8 lines\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYC0wTsPd0Vb",
        "outputId": "6b27eed3-9a1f-470b-856c-7717e030fa12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tapestry of code, so grand,\n",
            "LangChain's art, a helping hand.\n",
            "With LLMs it starts to weave,\n",
            "Complex chains we can conceive.\n",
            "\n",
            "From prompts to actions, flowing free,\n",
            "Memory's strength, for all to see.\n",
            "A builder's tool, with power keen,\n",
            "LangChain's magic, a wondrous scene.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import json\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\",api_key=GOOGLE_API_KEY,)\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to Telugu. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441f1075-0d48-4d31-b3aa-a21ede569f2e",
        "id": "tm3bcM0egdCx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‡∞®‡±á‡∞®‡±Å ‡∞™‡±ç‡∞∞‡±ã‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞ø‡∞Ç‡∞ó‡±ç ‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core"
      ],
      "metadata": {
        "id": "qn5nuLGfiMkq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternative way of Creating messages\n",
        "\n",
        "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage\n",
        "\n",
        "message=[\n",
        "    SystemMessage(content=\"You are a helpful assistant that translates English to Telugu. Translate the user sentence.\"),\n",
        "    HumanMessage(content=\"I love programming.\"),\n",
        "    AIMessage(content=\"In Telugu : ‡∞®‡∞æ‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡±ã‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞ø‡∞Ç‡∞ó‡±ç ‡∞Ö‡∞Ç‡∞ü‡±á ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞á‡∞∑‡±ç‡∞ü‡∞Ç \\n (NƒÅku pr≈çgrƒÅmi·πÅg a·πá·π≠ƒì cƒÅlƒÅ i·π£·π≠a·πÅ.).\"),\n",
        "    HumanMessage(content=\"I am an AI/ML Engineer\")\n",
        "]\n",
        "response = llm.invoke(message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IUV4dxAi8a4",
        "outputId": "23588671-ef79-48a2-ceac-c7b2058ef6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Telugu: ‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï AI/ML ‡∞á‡∞Ç‡∞ú‡∞®‡±Ä‡∞∞‡±ç‚Äå‡∞®‡∞ø.\n",
            "(Nƒìnu oka AI/ML i√±jinƒ´rni.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langchain Prompts**"
      ],
      "metadata": {
        "id": "XuXMppu7ABta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí° What are Prompt Templates?\n",
        "\n",
        "A Prompt Template is a **pre-structured prompt** where you can insert values later.  \n",
        "Think of it like a form: you design the structure once and fill in the blanks whenever you need.\n"
      ],
      "metadata": {
        "id": "Z-2e2NIvkkto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hK7E-aNLBiBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `ChatPromptTemplate` class"
      ],
      "metadata": {
        "id": "gRnp2uuBEMoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `from_template` to build a ChatPromptTemplate\n"
      ],
      "metadata": {
        "id": "XyJvxjFvARLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#langchain prompts\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"You are a helpful assistant that translates {input_language} to {output_language} and the text to translate is : {text}.\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt_value = prompt.invoke({\"input_language\":\"English\",\"output_language\":\"Hindi\",\"text\":\"My friend is a Full stack developer\"})\n",
        "\n",
        "response = llm.invoke(prompt_value)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFBP-rr4BYjD",
        "outputId": "02aca9f6-3cb1-4ab9-8b27-5eed6bffcaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the Hindi translation of \"My friend is a Full stack developer\":\n",
            "\n",
            "**‡§Æ‡•á‡§∞‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§è‡§ï ‡§´‡•Å‡§≤ ‡§∏‡•ç‡§ü‡•à‡§ï ‡§°‡•á‡§µ‡§≤‡§™‡§∞ ‡§π‡•à‡•§**\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "*   **‡§Æ‡•á‡§∞‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§** (Mera dost) - My friend\n",
            "*   **‡§è‡§ï** (ek) - a\n",
            "*   **‡§´‡•Å‡§≤ ‡§∏‡•ç‡§ü‡•à‡§ï ‡§°‡•á‡§µ‡§≤‡§™‡§∞** (Full stack developer) - Full stack developer (this term is often used as is in Hindi, or you could translate it more literally, but \"Full stack developer\" is very common)\n",
            "*   **‡§π‡•à** (hai) - is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = prompt.invoke({\"input_language\":\"Telugu\",\"output_language\":\"Hindi\",\"text\":\"‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï AI/ML ‡∞á‡∞Ç‡∞ú‡∞®‡±Ä‡∞∞‡±ç\"})\n",
        "response = llm.invoke(prompt_value)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vrI_goDlOB",
        "outputId": "6a2cfb62-108b-4c1e-9e05-310ccb6865b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the translation of \"‡∞®‡±á‡∞®‡±Å ‡∞í‡∞ï AI/ML ‡∞á‡∞Ç‡∞ú‡∞®‡±Ä‡∞∞‡±ç\" from Telugu to Hindi:\n",
            "\n",
            "**‡§Æ‡•à‡§Ç ‡§è‡§ï AI/ML ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•Ç‡§Å‡•§**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `from_messages` to build a ChatPromptTemplate\n"
      ],
      "metadata": {
        "id": "dDy8oj71Bqtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_messages=[\n",
        "    (\"system\", \"You are a professional and helpful assistant that translates {input_language} to {output_language}. Translate the given user sentence.\"),\n",
        "    (\"human\", \"The text to translate is : {text}\"),\n",
        "]\n",
        "prompt_template_with_messages = ChatPromptTemplate.from_messages(template_messages)\n",
        "prompt_value = prompt_template_with_messages.invoke({\"input_language\":\"English\",\"output_language\":\"Hindi\",\"text\":\"My friend is a Full stack developer\"})\n",
        "print(prompt_value)\n",
        "# response = llm.invoke(prompt_value)\n",
        "# print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O1s4wwKGB9h",
        "outputId": "e10a60e0-63be-49dc-cf12-b8735c4a71a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='You are a professional and helpful assistant that translates English to Hindi. Translate the given user sentence.', additional_kwargs={}, response_metadata={}), HumanMessage(content='The text to translate is : My friend is a Full stack developer', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `PromptTemplate` class"
      ],
      "metadata": {
        "id": "vjmoJqScED3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"Explain the topic {topic} in 5 simple lines to a {age}-year-old.\"\n",
        "prompt = PromptTemplate(\n",
        "    template = template,\n",
        "    input_variables = [\"topic\",\"age\"],\n",
        "    partial_variables = {\"age\":\"10\"}\n",
        "\n",
        ")\n",
        "prompt_value = prompt.invoke({\"topic\":\"AI\"})\n",
        "print(prompt_value)\n",
        "response = llm.invoke(prompt_value)\n",
        "print(response.content)\n",
        "\n",
        "#chain method\n",
        "\n",
        "# chain = prompt | llm\n",
        "# response = chain.invoke({\"topic\":\"AI\"})\n",
        "# print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljyb-D-QZiZE",
        "outputId": "b1a403ec-d46c-4f46-b4ce-89e56e8160d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Explain the topic AI in 5 simple lines to a 10-year-old.'\n",
            "Imagine a super-smart computer that can learn and think like a person!\n",
            "\n",
            "It can recognize pictures, understand what you say, and even play games.\n",
            "\n",
            "AI helps make things like video games and robots more clever.\n",
            "\n",
            "It's like giving computers a brain to solve problems and help us.\n",
            "\n",
            "But it's still learning and getting better all the time!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(response)\n",
        "# print(json.dumps(response.dict(),indent=2))"
      ],
      "metadata": {
        "id": "EnO2bt8mdR0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Schema-Guided Responses with `with_structured_output`**"
      ],
      "metadata": {
        "id": "x2WALT4-FSOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí° Schema-Guided Responses (`with_structured_output`)\n",
        "\n",
        "`with_structured_output` lets you tell the model **exactly what shape the output should follow**‚Äîlike a form or schema.\n",
        "Instead of free text, the model responds in a **structured format** (like JSON with specific fields).\n",
        "This makes the output **predictable, clean, and easy to use in code.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5nUc9GqBk9hZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TypedDict**"
      ],
      "metadata": {
        "id": "f_apzJhyFVRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class Person(TypedDict):\n",
        "  name:str\n",
        "  age: int\n",
        "p1:Person = {\"name\":\"John\",\"age\":30}\n",
        "print(p1)\n",
        "print(type(p1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfBD4vYjCSVv",
        "outputId": "35e59d50-aaec-4a32-87cb-4c1744c0e27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'John', 'age': 30}\n",
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict,Annotated,Literal\n",
        "\n",
        "class Review(TypedDict):\n",
        "  sentiment: Annotated[Literal['positive', 'neutral', 'negative'],\"Overall sentiment of The review\"]  # e.g., 'positive', 'neutral', 'negative'\n",
        "  summary: str    # A concise summary of the review\n",
        "  rating: float   # Numerical rating given by the reviewer\n",
        "  rating_scale: str  # Scale used for the rating, e.g., '1-5', '0-10'"
      ],
      "metadata": {
        "id": "KBmxdyblIzKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_input = \"\"\"Karthik Gattamneni crafts an ambitious film that blends ancient mythology with modern superhero storytelling. The tale begins centuries ago, when Emperor Ashoka, shaken by the bloodshed of the Kalinga war, seals the secret of immortality within nine sacred books and entrusts them to loyal guardians.\n",
        "Teja Sajja, following his success in Hanu-Man, delivers a solid performance as Vedha. Manchu Manoj shines as Mahabir Lama ‚Äî a character shaped by caste-based prejudice and societal rejection. His arc adds emotional complexity, blurring the lines between villainy and vengeance. Is he evil, or simply a man pushed to darkness by years of humiliation?\n",
        "Visually, the film excels. The Sampati bird sequence and the high-octane train fight stand out as technical highlights, showcasing Gattamneni‚Äôs skill as a cinematographer. These moments elevate the film‚Äôs scale and immerse the audience in its mythic world.\n",
        "Supporting performances by Jagapathi Babu, Jayaram and Shriya Saran add weight to Vedha‚Äôs journey. Ritika Nayak does well in a limited role as Vibha, while Gowra Hari‚Äôs background score enhances the epic tone.\n",
        "However, the screenplay falters at times with unnecessary comedic detours that slow the pacing. The climax, though emotionally grounded, feels predictable and lacks the punch needed to elevate the finale.\n",
        "Despite some narrative flaws, the film stands out for its visual grandeur, mythological depth, and strong performances ‚Äî making it a worthwhile watch, especially for fans of stylised, myth-inspired superhero tales.\"\"\""
      ],
      "metadata": {
        "id": "TUdhj0OZJpDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_model = llm.with_structured_output(Review)\n",
        "response1 = structured_model.invoke(review_input)\n",
        "print(response1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fTHuAUgKNr8",
        "outputId": "2f3563e1-f2e5-4867-b6f7-6216e3bead95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rating': 3.5, 'sentiment': 'positive', 'rating_scale': '5 stars', 'summary': \"Karthik Gattamneni's film is an ambitious blend of ancient mythology and modern superhero storytelling, featuring strong performances from Teja Sajja and Manchu Manoj. The visuals are a major highlight, particularly the Sampati bird sequence and the train fight. While the screenplay has pacing issues and a predictable climax, the film's visual grandeur and mythological depth make it a worthwhile watch for fans of the genre.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pydantic**"
      ],
      "metadata": {
        "id": "degnhitxmse6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel,Field\n",
        "from typing import TypedDict,Annotated,Literal\n",
        "\n",
        "class Person(BaseModel):\n",
        "  name:str\n",
        "  age:int"
      ],
      "metadata": {
        "id": "iNsNxnLnm9_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = {\"name\":\"Viswa\",\"age\":16}\n",
        "po=Person(**p)\n",
        "print(po)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DcwFvTRq76s",
        "outputId": "8c200130-965f-4d3c-fae1-9b9d51fb68ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='Viswa' age=16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewPydantic(BaseModel):\n",
        "    sentiment: Annotated[\n",
        "        Literal['positive', 'neutral', 'negative'],\n",
        "        \"Overall sentiment of the review\"\n",
        "    ]\n",
        "    summary: Annotated[\n",
        "        str,\n",
        "        \"A concise summary of the review\"\n",
        "    ]\n",
        "    rating: Annotated[\n",
        "        float,\n",
        "        Field(..., ge=0, le=5, description=\"Numerical rating given by the reviewer (0 to 5)\")\n",
        "    ]\n",
        "\n",
        "smodel_with_pydantic = llm.with_structured_output(ReviewPydantic)\n",
        "response2 = smodel_with_pydantic.invoke(review_input)\n",
        "print(response2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQBJBn3aBEjx",
        "outputId": "52d703f8-0023-4224-ee16-b75883ea4734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment='positive' summary='A visually grand film with mythological depth and strong performances, despite some pacing issues in the screenplay and a predictable climax.' rating=4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**JSON**"
      ],
      "metadata": {
        "id": "7xLI-x_UqsCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_json_schema = {\n",
        "  \"title\": \"Generated schema for Review\",\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"summary\": {\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"A concise summary of the review\" #Just like \"Annotated\" in JSON\n",
        "    },\n",
        "    \"sentiment\": {\n",
        "      \"type\": \"string\",\n",
        "      \"enum\" : [\"hit\",\"flop\"], #Just like \"Literal\" in JSON\n",
        "      \"description\": \"Overall sentiment of the review\"\n",
        "    },\n",
        "    \"rating\": {\n",
        "      \"type\": \"number\",\n",
        "      \"description\": \"Numerical rating given by the reviewer (0 to 5)\"\n",
        "    },\n",
        "    \"rating_scale\": {\n",
        "      \"type\": \"string\",\n",
        "      \"enum\": [\"1-5\",\"0-10\"],\n",
        "      \"description\": \"Scale used for the rating, e.g., '1-5', '0-10'\"\n",
        "    }\n",
        "  },\n",
        "  \"required\": [\n",
        "    \"summary\",\n",
        "    \"sentiment\",\n",
        "    \"rating\",\n",
        "    \"rating_scale\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "# smodel_with_json = llm.with_structured_output(review_json_schema)\n",
        "# response3 = smodel_with_json.invoke(review_input)\n",
        "# print(response3)\n",
        "\n",
        "\n",
        "\n",
        "#Gemini doesn't support JSON Mode"
      ],
      "metadata": {
        "id": "EBojWyNnd9Mx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Output Parser**"
      ],
      "metadata": {
        "id": "qmQPGl0fvAkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üí° What Are Output Parsers?\n",
        "\n",
        "Output Parsers help convert the model‚Äôs raw text into a **clean, usable format**‚Äîlike plain text, JSON, or a Python object.\n",
        "They make LLM outputs easier to handle in pipelines and agent workflows.\n",
        "\n",
        "<br>\n",
        "\n",
        "# Short Explanation Per Parser\n",
        "\n",
        "### **‚Ä¢ `StrOutputParser`**\n",
        "\n",
        "Converts the model‚Äôs answer into clean plain text.\n",
        "\n",
        "### **‚Ä¢ `JsonOutputParser`**\n",
        "\n",
        "Parses the response into JSON (dictionary) you can use in code.\n",
        "\n",
        "### **‚Ä¢ `StructuredOutputParser`**\n",
        "\n",
        "Enforces a more strict schema using JSON Schema.\n",
        "\n",
        "### **‚Ä¢ `PydanticOutputParser`**\n",
        "\n",
        "Parses the output into a **typed Python class** (Pydantic model), great for agents.\n"
      ],
      "metadata": {
        "id": "n-TRg-ISlt07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**String Output Parser**"
      ],
      "metadata": {
        "id": "VMthOLbxHuri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser =StrOutputParser()\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "response = chain.invoke({\"topic\":\"AI\"})\n",
        "print(response)\n",
        "\n",
        "# print(json.dumps(response,indent=2))\n",
        "# ---> json.dumps only knows how to serialize basic types (dict, list, str, int, etc.).\n",
        "# ---> LangChain‚Äôs BaseMessage classes (like AIMessage, HumanMessage, SystemMessage) implement a .dict() method.\n",
        "# print(response) // Raw ---> Formatted\n",
        "# print(json.dumps(response.dict(),indent=2))\n",
        "\n",
        "# TL;DR (I know you‚Äôre lazy üòé !!):\n",
        "# üß† Without parser ‚Üí llm returns AIMessage (object with .content)\n",
        "# üßæ With StrOutputParser ‚Üí extracts .content ‚Üí plain str output ‚úÖ\n",
        "# üí° So response is string, no need .dict() or json.dumps()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNuAk4wDH_9N",
        "outputId": "179ebe50-40e1-458c-efb6-555adb57fd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine a computer that can learn and think like you!\n",
            "\n",
            "It's like giving a robot a super smart brain.\n",
            "\n",
            "AI can help computers understand pictures, sounds, and even words.\n",
            "\n",
            "It's used in video games to make characters act real, and in phones to understand your voice.\n",
            "\n",
            "Basically, AI is making computers smarter so they can do amazing new things!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**JSON Output Parser**"
      ],
      "metadata": {
        "id": "eH46ulqlIGBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "json_parser = JsonOutputParser()\n",
        "\n",
        "template = \"Explain the topic {topic} in 5 simple lines to a {age}-year-old.Follow the format Instructions attached : {format_instructions}\"\n",
        "prompt = PromptTemplate(\n",
        "    template = template,\n",
        "    input_variables = [\"topic\",\"age\"],\n",
        "    partial_variables = {\"age\":\"10\",\"format_instructions\":json_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chain = prompt | llm | json_parser\n",
        "response = chain.invoke({\"topic\":\"Indian Music\",\"age\":20})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axHwnUHpIPn3",
        "outputId": "8194e3a9-dc37-4f35-b199-ace2b7ec013e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'topic': 'Indian Music', 'explanation': ['Think of Indian music as having two main branches: Hindustani (from the North) and Carnatic (from the South), each with its own distinct feel and structures.', \"It's heavily based on 'ragas' (melodic frameworks) and 'talas' (rhythmic cycles), giving it a unique, improvisational, and intricate sound.\", 'Instruments like the sitar, tabla, and veena are iconic, but vocals are often the heart of the performance, carrying the melody and emotion.', \"It's deeply spiritual and philosophical, often reflecting ancient traditions, stories, and emotions through its melodies.\", 'From classical masterpieces to Bollywood soundtracks, Indian music is incredibly diverse and continues to evolve, influencing sounds globally.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#without chain for json parser\n",
        "chain = prompt | llm\n",
        "response = chain.invoke({\"topic\":\"Western Music\",\"age\":20})\n",
        "\n",
        "parsed_output = json_parser.invoke(response.content)\n",
        "print(parsed_output)\n",
        "\n",
        "parsed_output = json_parser.parse(response.content)\n",
        "print(parsed_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKfNcnpKMQSj",
        "outputId": "0a330db8-c5ad-405f-8bcc-37b94b20a2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'topic': 'Western Music', 'explanation': ['Think of it as the music most commonly heard in movies, on the radio, and in concerts from Europe and its cultural offshoots (like North America).', \"It's evolved over centuries, from ancient chants to complex classical symphonies and the pop, rock, and electronic music you hear today.\", 'Key elements include melody (the tune), harmony (how notes sound together), rhythm (the beat), and structure (how songs are organized).', \"It's incredibly diverse, encompassing everything from the dramatic operas of Mozart to the energetic beats of EDM.\", \"Basically, it's the musical language that has shaped much of the global soundscape we're familiar with.\"]}\n",
            "{'topic': 'Western Music', 'explanation': ['Think of it as the music most commonly heard in movies, on the radio, and in concerts from Europe and its cultural offshoots (like North America).', \"It's evolved over centuries, from ancient chants to complex classical symphonies and the pop, rock, and electronic music you hear today.\", 'Key elements include melody (the tune), harmony (how notes sound together), rhythm (the beat), and structure (how songs are organized).', \"It's incredibly diverse, encompassing everything from the dramatic operas of Mozart to the energetic beats of EDM.\", \"Basically, it's the musical language that has shaped much of the global soundscape we're familiar with.\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Structured Output Parser**"
      ],
      "metadata": {
        "id": "p_bG-pa4Y1KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser,ResponseSchema\n",
        "\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"topic\", description=\"The explained topic in 5 simple lines\"),\n",
        "    ResponseSchema(name=\"summary\", description=\"A 1-2 line overall summary of the topic\"),\n",
        "    ResponseSchema(name=\"analogy\", description=\"A simple analogy or metaphor appropriate for the given age\"),\n",
        "    ResponseSchema(name=\"keywords\", description=\"List of 3‚Äì5 important keywords from the topic\"),\n",
        "]\n",
        "\n",
        "structured_output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "#prints instructions\n",
        "print(structured_output_parser.get_format_instructions())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaw73McRY6oY",
        "outputId": "a22c4811-64d4-4630-8eeb-f1d77f9f55a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"topic\": string  // The explained topic in 5 simple lines\n",
            "\t\"summary\": string  // A 1-2 line overall summary of the topic\n",
            "\t\"analogy\": string  // A simple analogy or metaphor appropriate for the given age\n",
            "\t\"keywords\": string  // List of 3‚Äì5 important keywords from the topic\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Explain the topic {topic} in 5 simple lines to a {age}-year-old.Follow the format Instructions attached : {format_instructions}\"\n",
        "prompt = PromptTemplate(\n",
        "    template = template,\n",
        "    input_variables = [\"topic\",\"age\"],\n",
        "    partial_variables = {\"age\":\"10\",\"format_instructions\":structured_output_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chain = prompt | llm | structured_output_parser\n",
        "response = chain.invoke({\"topic\":\"Indian Music\",\"age\":20})\n",
        "print(type(response))\n",
        "print(json.dumps(response , indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjZTW_dtkNdu",
        "outputId": "cee80297-c1f0-467a-d3d3-da716992f49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{\n",
            "  \"topic\": \"Indian music is super diverse, blending ancient traditions with modern influences.\\nIt's often built around melodic structures called 'ragas' and rhythmic cycles called 'talas'.\\nThink of it as a conversation between instruments and voices, with a lot of improvisation.\\nIt can be classical (like Carnatic and Hindustani), folk, or film music, each with its own vibe.\\nIt's a rich cultural expression that's been evolving for thousands of years.\",\n",
            "  \"summary\": \"Indian music is a vibrant and ancient tradition characterized by melodic frameworks (ragas), rhythmic patterns (talas), and a strong emphasis on improvisation across its many forms.\",\n",
            "  \"analogy\": \"Imagine Indian music like a really cool, intricate recipe. The 'ragas' are the core ingredients, the 'talas' are the cooking steps, and the musicians improvise to create unique, delicious dishes every time.\",\n",
            "  \"keywords\": \"Raga, Tala, Improvisation, Classical Indian Music, Bollywood Music\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.get_graph().print_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5OKkBDyVEx_",
        "outputId": "e0cb0522-4231-4a9e-d106-4f9096e58055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        +-------------+          \n",
            "        | PromptInput |          \n",
            "        +-------------+          \n",
            "                *                \n",
            "                *                \n",
            "                *                \n",
            "       +----------------+        \n",
            "       | PromptTemplate |        \n",
            "       +----------------+        \n",
            "                *                \n",
            "                *                \n",
            "                *                \n",
            "   +------------------------+    \n",
            "   | ChatGoogleGenerativeAI |    \n",
            "   +------------------------+    \n",
            "                *                \n",
            "                *                \n",
            "                *                \n",
            "   +------------------------+    \n",
            "   | StructuredOutputParser |    \n",
            "   +------------------------+    \n",
            "                *                \n",
            "                *                \n",
            "                *                \n",
            "+------------------------------+ \n",
            "| StructuredOutputParserOutput | \n",
            "+------------------------------+ \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pydantic Output Parser**"
      ],
      "metadata": {
        "id": "-2cqa3IGiwTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel,Field\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from typing import List\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class TopicResolution(BaseModel):\n",
        "    topic: str = Field(description=\"The name of the explained topic\")\n",
        "    summary: str = Field(description=\"A 1-2 line overall summary of the topic\")\n",
        "    analogy: str = Field(description=\"A simple analogy or metaphor appropriate for the given age\")\n",
        "    keywords: List[str] = Field(description=\"List of 3‚Äì5 important keywords from the topic\")\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=TopicResolution)\n",
        "print(pydantic_parser.get_format_instructions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWXwXbKOiyb6",
        "outputId": "60d21564-fd51-4974-f428-da0ee701d338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"topic\": {\"description\": \"The name of the explained topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"summary\": {\"description\": \"A 1-2 line overall summary of the topic\", \"title\": \"Summary\", \"type\": \"string\"}, \"analogy\": {\"description\": \"A simple analogy or metaphor appropriate for the given age\", \"title\": \"Analogy\", \"type\": \"string\"}, \"keywords\": {\"description\": \"List of 3‚Äì5 important keywords from the topic\", \"items\": {\"type\": \"string\"}, \"title\": \"Keywords\", \"type\": \"array\"}}, \"required\": [\"topic\", \"summary\", \"analogy\", \"keywords\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Explain the topic {topic} in 5 simple lines to a {age}-year-old.Follow the format Instructions attached : {format_instructions}\"\n",
        "prompt = PromptTemplate(\n",
        "    template = template,\n",
        "    input_variables = [\"topic\",\"age\"],\n",
        "    partial_variables = {\"age\":\"10\",\"format_instructions\":pydantic_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chain = prompt | llm | pydantic_parser\n",
        "response = chain.invoke({\"topic\":\"Indian Music\",\"age\":20})\n",
        "print(type(response))\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edc025e-7a1c-4052-e68b-ef4fc0339842",
        "id": "gqjP700PkXpZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.TopicResolution'>\n",
            "topic='Indian Music' summary=\"Indian music is ancient and diverse, built on melodic frameworks called 'ragas' and rhythmic cycles called 'talas'. It's deeply spiritual and expresses a wide range of emotions.\" analogy=\"Think of it like a complex recipe. The 'ragas' are the core spices and ingredients that define the flavor profile, while the 'talas' are the cooking steps and timings that give it structure and rhythm.\" keywords=['Raga', 'Tala', 'Melody', 'Rhythm', 'Spirituality']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.get_graph().print_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC4eYgYxPKFg",
        "outputId": "c4c011e6-37b7-4a99-cd9b-8443ed90231b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            " +----------------------+  \n",
            " | PydanticOutputParser |  \n",
            " +----------------------+  \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | TopicResolution |    \n",
            "    +-----------------+    \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chains** (Contd..)"
      ],
      "metadata": {
        "id": "5s2bsbIyF6Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential Chain"
      ],
      "metadata": {
        "id": "mK9VyW0jMgIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize StrOutputParser\n",
        "str_parser = StrOutputParser()\n",
        "\n",
        "template_1 = \"\"\"You are a professional linguist and translation specialist.\n",
        "Translate the provided text from {input_language} into {output_language},\n",
        "ensuring accuracy and preserving tone.\n",
        "\n",
        "Translate the following review:\n",
        "{review}\n",
        "\n",
        "Provide only the translated review in {output_language}. Do not add explanations or commentary.\"\"\"\n",
        "\n",
        "template_2 = \"\"\"\n",
        "You are a professional content summarizer.\n",
        "Summarize the provided reviewinto bullet points in the same language,\n",
        "ensuring that the key points and important details are preserved,\n",
        "while keeping the summary concise and easy to read.\n",
        "\n",
        "Review to summarize:\n",
        "{review}\n",
        "\n",
        "Provide only the summarized review. Do not add explanations or commentary.\n",
        "\"\"\"\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template=template_1,\n",
        "    input_variables=[\"input_language\", \"output_language\", \"review\"]\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template=template_2,\n",
        "    input_variables=[\"review\"]\n",
        ")\n",
        "\n",
        "review_input = \"\"\"\n",
        "As someone who grew up with the original Lilo & Stitch, I wasn't sure what to expect from the 2025 remake-but wow, this movie absolutely delivered. It's heartfelt, beautifully made, and captures the spirit of the original while adding just the right amount of freshness.\n",
        "\n",
        "This is the kind of remake we actually want-one made with care, love, and deep respect for the source material. The emotional themes about family, love, and belonging are still front and center, and they hit just as hard today as they did years ago. Lilo's story is just as touching, Stitch is just as chaotic and adorable, and the message of \"ohana\" still resonates powerfully.\n",
        "\n",
        "Visually, the movie is stunning. The Hawaiian setting feels authentic and vibrant, and the design of Stitch and the other alien characters blends surprisingly well with the real-world elements. It never feels forced or overly modernized. The music also keeps that nostalgic charm with new energy.\n",
        "\n",
        "I could tell the creators worked hard on this. It's not a cash grab-it's a genuine love letter to fans old and new. Whether you've seen the original or not, this remake stands tall on its own.\n",
        "\n",
        "This is probably the best Disney remake so far. 10/10. It's emotional, entertaining, and full of heart. A true example of how remakes should be.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "chain_1 = prompt1 | llm | str_parser\n",
        "chain_2 = prompt2 | llm | str_parser\n",
        "\n",
        "final_chain = chain_1 | chain_2\n",
        "response = final_chain.invoke({\"input_language\":\"English\",\"output_language\":\"Telugu\",\"review\":review_input})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tob1QLxQGEC4",
        "outputId": "cacb64d2-612a-4271-d5ae-b1cf6a44b1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   ‡∞Ö‡∞∏‡∞≤‡±Å \"‡∞≤‡±à‡∞≤‡±ã & ‡∞∏‡±ç‡∞ü‡∞ø‡∞ö‡±ç\" ‡∞Ö‡∞≠‡∞ø‡∞Æ‡∞æ‡∞®‡∞ø‡∞ó‡∞æ, 2025 ‡∞∞‡±Ä‡∞Æ‡±á‡∞ï‡±ç ‡∞Ü‡∞ï‡∞ü‡±ç‡∞ü‡±Å‡∞ï‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "*   ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ ‡∞π‡±É‡∞¶‡∞Ø‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï‡∞Ç‡∞ó‡∞æ, ‡∞Ö‡∞Ç‡∞¶‡∞Ç‡∞ó‡∞æ ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø, ‡∞Ö‡∞∏‡∞≤‡±Å ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ ‡∞∏‡±ç‡∞´‡±Ç‡∞∞‡±ç‡∞§‡∞ø‡∞®‡∞ø ‡∞®‡∞ø‡∞≤‡±Å‡∞™‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Ç ‡∞ï‡±ä‡∞§‡±ç‡∞§‡∞¶‡∞®‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø.\n",
            "*   ‡∞á‡∞¶‡∞ø ‡∞Æ‡±Ç‡∞≤ ‡∞ï‡∞•‡∞ï‡±Å ‡∞ó‡±å‡∞∞‡∞µ‡∞Ç ‡∞ö‡±Ç‡∞™‡±Å‡∞§‡±Ç, ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞§‡±ã, ‡∞ú‡∞æ‡∞ó‡±ç‡∞∞‡∞§‡±ç‡∞§‡∞ó‡∞æ ‡∞§‡±Ä‡∞∏‡∞ø‡∞® ‡∞∞‡±Ä‡∞Æ‡±á‡∞ï‡±ç.\n",
            "*   ‡∞ï‡±Å‡∞ü‡±Å‡∞Ç‡∞¨‡∞Ç, ‡∞™‡±ç‡∞∞‡±á‡∞Æ, ‡∞Ö‡∞®‡±Å‡∞¨‡∞Ç‡∞ß‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞≠‡∞æ‡∞µ‡±ã‡∞¶‡±ç‡∞µ‡±á‡∞ó‡∞æ‡∞≤‡±Å ‡∞á‡∞™‡±ç‡∞™‡∞ü‡∞ø‡∞ï‡±Ä ‡∞¨‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø.\n",
            "*   ‡∞≤‡±à‡∞≤‡±ã ‡∞Æ‡∞®‡±ã‡∞π‡∞∞‡∞Ç‡∞ó‡∞æ, ‡∞∏‡±ç‡∞ü‡∞ø‡∞ö‡±ç ‡∞Ö‡∞≤‡±ç‡∞≤‡∞∞‡∞ø‡∞ó‡∞æ, \"‡∞í‡∞π‡∞æ‡∞®‡∞æ\" ‡∞∏‡∞Ç‡∞¶‡±á‡∞∂‡∞Ç ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø.\n",
            "*   ‡∞π‡∞µ‡∞æ‡∞Ø‡∞ø ‡∞®‡±á‡∞™‡∞•‡±ç‡∞Ø‡∞Ç ‡∞™‡±ç‡∞∞‡∞æ‡∞Æ‡∞æ‡∞£‡∞ø‡∞ï‡∞Ç‡∞ó‡∞æ, ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n",
            "*   ‡∞∏‡±ç‡∞ü‡∞ø‡∞ö‡±ç ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞á‡∞§‡∞∞ ‡∞ó‡±ç‡∞∞‡∞π‡∞æ‡∞Ç‡∞§‡∞∞ ‡∞™‡∞æ‡∞§‡±ç‡∞∞‡∞≤ ‡∞∞‡±Ç‡∞™‡∞ï‡∞≤‡±ç‡∞™‡∞® ‡∞µ‡∞æ‡∞∏‡±ç‡∞§‡∞µ ‡∞™‡±ç‡∞∞‡∞™‡∞Ç‡∞ö‡∞Ç‡∞§‡±ã ‡∞¨‡∞æ‡∞ó‡∞æ ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø‡∞™‡±ã‡∞Ø‡∞ø‡∞Ç‡∞¶‡∞ø, ‡∞Ö‡∞§‡∞ø‡∞ó‡∞æ ‡∞Ü‡∞ß‡±Å‡∞®‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞®‡∞ü‡±ç‡∞≤‡±Å ‡∞Ö‡∞®‡∞ø‡∞™‡∞ø‡∞Ç‡∞ö‡∞≤‡±á‡∞¶‡±Å.\n",
            "*   ‡∞∏‡∞Ç‡∞ó‡±Ä‡∞§‡∞Ç ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞§‡±ã ‡∞®‡∞æ‡∞∏‡±ç‡∞ü‡∞æ‡∞≤‡±ç‡∞ú‡∞ø‡∞ï‡±ç ‡∞Ü‡∞ï‡∞∞‡±ç‡∞∑‡∞£‡∞®‡±Å ‡∞ï‡±ä‡∞®‡∞∏‡∞æ‡∞ó‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "*   ‡∞á‡∞¶‡∞ø ‡∞°‡∞¨‡±ç‡∞¨‡±Å ‡∞∏‡∞Ç‡∞™‡∞æ‡∞¶‡∞ø‡∞Ç‡∞ö‡±á ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞Ç ‡∞ï‡∞æ‡∞ï‡±Å‡∞Ç‡∞°‡∞æ, ‡∞™‡∞æ‡∞§, ‡∞ï‡±ä‡∞§‡±ç‡∞§ ‡∞Ö‡∞≠‡∞ø‡∞Æ‡∞æ‡∞®‡±Å‡∞≤‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞≤‡±á‡∞ñ.\n",
            "*   ‡∞Ö‡∞∏‡∞≤‡±Å ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ ‡∞ö‡±Ç‡∞∏‡∞ø‡∞®‡∞æ ‡∞ö‡±Ç‡∞°‡∞ï‡∞™‡±ã‡∞Ø‡∞ø‡∞®‡∞æ, ‡∞à ‡∞∞‡±Ä‡∞Æ‡±á‡∞ï‡±ç ‡∞¶‡∞æ‡∞®‡∞ø‡∞ï‡∞¶‡±á ‡∞®‡∞ø‡∞≤‡±Å‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø.\n",
            "*   ‡∞á‡∞¶‡∞ø ‡∞¨‡∞π‡±Å‡∞∂‡∞æ ‡∞Ö‡∞§‡±ç‡∞Ø‡±Å‡∞§‡±ç‡∞§‡∞Æ ‡∞°‡∞ø‡∞∏‡±ç‡∞®‡±Ä ‡∞∞‡±Ä‡∞Æ‡±á‡∞ï‡±ç, 10/10.\n",
            "*   ‡∞á‡∞¶‡∞ø ‡∞≠‡∞æ‡∞µ‡±ã‡∞¶‡±ç‡∞µ‡±á‡∞ó‡∞≠‡∞∞‡∞ø‡∞§‡∞Ç‡∞ó‡∞æ, ‡∞µ‡∞ø‡∞®‡±ã‡∞¶‡∞æ‡∞§‡±ç‡∞Æ‡∞ï‡∞Ç‡∞ó‡∞æ, ‡∞π‡±É‡∞¶‡∞Ø‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_chain.get_graph().print_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CKUR6Ch-_DX",
        "outputId": "3ef170b0-8db5-4d0e-ebf8-47511503c1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "The setup works only because `prompt2` is a `PromptTemplate` with a single input variable. Since we use `StrOutputParser`, the previous chain produces a single output, which LangChain can automatically map to the single input of `prompt2` under the hood.\n",
        "\n",
        "If `prompt2` required more than one input variable, LangChain would fail to map the single output to multiple inputs and would raise a `TypeError`.\n"
      ],
      "metadata": {
        "id": "Y02XtlMEFu1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parallel Chains"
      ],
      "metadata": {
        "id": "xMU1XLRGlJal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_input = \"\"\"I was waiting for the release of the dubbed version of Doraemon's this movie since a long time and now that it finally released, i couldn't hold myself from watching it.\n",
        "\n",
        "And it was just the bestest movie i would say I've watched. Waiting worths it all as it was not only fun-filled but also conveyed a very important message which I deeply understood and would want you guys to understand too.\n",
        "\n",
        "So here's, How It Taught Me the Value of Imperfections:\n",
        "\n",
        "I've always believed that Doraemon movies have a special kind of magic. They never fail to entertain, to touch my heart, and to leave me with something meaningful. But this movie is different. It's not just a magical adventure or a fun journey in the skies which gave me entertainment but gave a lesson.\n",
        "\n",
        "Nobita's Sky Utopia was different. It wasn't just another movie; it was a lesson in life-a lesson that I didn't realize I needed until I watched it. It gave a profound reminder that being human means being imperfect, and that our flaws aren't weaknesses-they're what connect us to others, to feelings, to empathy, to love.\n",
        "\n",
        "What this film portrayed so powerfully is the beauty of human imperfections. It made me realize that our flaws-the ones we often try to hide or hate-are actually essential. They're what make us human.\n",
        "\n",
        "Our hearts, with all their chaos, pain, and softness, are what guide us through life more than our logic ever can. The message that perfection might look beautiful, but it's emotionless, mechanical, and unfeeling-that was portrayed so powerfully in this movie. Without flaws, we wouldn't feel love, compassion, growth, or understanding. Without conflict, there would be no evolution-within ourselves or in society. Without them, we wouldn't be able to love deeply, feel compassion, understand pain, or truly connect with others. Perfection might look ideal, but it's lifeless. It's our imperfections that make our hearts alive.\n",
        "\n",
        "The message that every decision doesn't have to be logical-that our heart, with all its messiness, matters too-was so clearly and beautifully shown. I've been struggling lately with my own flaws, with conflict in my family, and with painful thoughts about myself and the world. But this movie brought me hope. It reminded me that maybe we're not supposed to be perfect. Maybe we're just meant to try, to learn, and to grow through our mistakes and feelings.\n",
        "\n",
        "There's a part in the movie where Nobita sees his friends-Shizuka, Gian, and Suneo-change under Dr. Ray's manipulation. At first, the change seems ideal: they're no longer fighting, no more teasing, no more chaos. It looks perfect. But as time passes, Nobita realizes that he misses their flaws-their imperfections, the very things that used to annoy him. And it made me realize something so powerful: sometimes, the flaws that irritate us the most are the very things that make those people unforgettable.\n",
        "\n",
        "It's so easy to get frustrated with the imperfections of those around us, but when they're gone, we realize that those imperfections are the very traits that make us love them. The quirks, the annoyances, the little things that make someone who they are. These flaws aren't just mistakes; they're parts of the magic of being human.\n",
        "\n",
        "So, we should try to handle our emotions before pointing the flaws of others because once they're lost, we might realize their value.\n",
        "\n",
        "This movie brought me back to a memory of a friend I have-a friend who used to be so talkative, so obsessed with being around me. Back then, it felt overwhelming at times, even irritating. But now, something's changed. She's quieter. And honestly, I miss the version of her who couldn't stop talking, who would fill up the space with her energy and love. I didn't realize it then, but her flaws were what made her special to me.\n",
        "\n",
        "This movie reminded me that imperfections are necessary. They aren't something to be ashamed of. In fact, they are what make our relationships real and meaningful. If everything was perfect, we wouldn't be able to feel the love, the connection, the depth that comes with imperfection.\n",
        "\n",
        "It helped me want to live. To survive. To embrace life with all its pain and beauty.\n",
        "\n",
        "So, to the creators of Nobita's Sky Utopia, thank you for bringing this beautiful lesson to life.\n",
        "\n",
        "Thank you, from the deepest corner of my heart, for creating such a powerful film. It's a story that will stay with me forever. It made me appreciate the people in my life, flaws and all, and reminded me to embrace the chaos and imperfections that come with being human. Sometimes, it's those very flaws that connect us in the most profound way.\n",
        "\n",
        "I truly encourage everyone to watch Nobita's Sky Utopia. It's not just a Doraemon adventure-it's a lesson in being human.\"\"\""
      ],
      "metadata": {
        "id": "SCRoC3Oipb9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_1 = \"\"\"You are a professional linguist and translation specialist.\n",
        "Translate the provided text from {input_language} into {output_language},\n",
        "ensuring accuracy and preserving tone.\n",
        "\n",
        "Translate the following review:\n",
        "{review}\n",
        "\n",
        "Provide only the translated review in {output_language}. Do not add explanations or commentary.\"\"\"\n",
        "\n",
        "template_2 = \"\"\"You are a professional content curator and social media specialist.\n",
        "Generate a set of relevant and engaging hashtags based on the provided review,\n",
        "ensuring they reflect its key themes, sentiment, and tone.\n",
        "\n",
        "Review:\n",
        "{review}\n",
        "\n",
        "Provide only the hashtags, separated by spaces. Do not add explanations or commentary.\"\"\"\n",
        "\n",
        "template_3 = \"\"\"You are a professional content strategist.\n",
        "Summarize the provided review in the same language and also in a concise and engaging way, keeping its key sentiment and tone.\n",
        "Do not modify or add to the provided hashtags ‚Äî keep them exactly as they are.\n",
        "\n",
        "Review:\n",
        "{translated_review}\n",
        "\n",
        "Hashtags:\n",
        "{hashtags}\n",
        "\n",
        "Output format:\n",
        "Summary: <summarized review>\n",
        "Hashtags: {hashtags}\n",
        "\n",
        "Do not add explanations or commentary.\"\"\""
      ],
      "metadata": {
        "id": "l6GZrkcxFwNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableParallel\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template=template_1,\n",
        "    input_variables=[\"input_language\", \"output_language\", \"review\"]\n",
        ")\n",
        "prompt2 = PromptTemplate(\n",
        "    template=template_2,\n",
        "    input_variables=[\"review\"]\n",
        ")\n",
        "prompt3 = PromptTemplate(\n",
        "    template=template_3,\n",
        "    input_variables=[\"translated_review\", \"hashtags\"]\n",
        ")\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "  \"translated_review\":prompt1 | llm | parser,\n",
        "    \"hashtags\":prompt2 | llm | parser,\n",
        "})\n",
        "\n",
        "sequentiual_chain = prompt3 | llm | parser\n",
        "final_chain = parallel_chain | sequentiual_chain\n",
        "response = final_chain.invoke({\"input_language\":\"English\",\"output_language\":\"Telugu\",\"review\":review_input})\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "KBQBT8KgoLbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output will be:\n",
        "\n",
        "# Summary: ‡∞é‡∞Ç‡∞§‡±ã ‡∞ï‡∞æ‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞é‡∞¶‡±Å‡∞∞‡±Å‡∞ö‡±Ç‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞® ‡∞°‡±ã‡∞∞‡∞æ‡∞Æ‡±ã‡∞®‡±ç ‡∞∏‡∞ø‡∞®‡∞ø‡∞Æ‡∞æ, \"‡∞®‡±ã‡∞¨‡∞ø‡∞§‡∞æ ‡∞∏‡±ç‡∞ï‡±à ‡∞Ø‡±Ç‡∞ü‡±ã‡∞™‡∞ø‡∞Ø‡∞æ\" ‡∞µ‡∞ø‡∞°‡±Å‡∞¶‡∞≤‡±à‡∞® ‡∞§‡∞∞‡±ç‡∞µ‡∞æ‡∞§, ‡∞á‡∞¶‡∞ø ‡∞ï‡±á‡∞µ‡∞≤‡∞Ç ‡∞µ‡∞ø‡∞®‡±ã‡∞¶‡∞Æ‡±á ‡∞ï‡∞æ‡∞ï‡±Å‡∞Ç‡∞°‡∞æ, ‡∞Æ‡∞æ‡∞®‡∞µ ‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞‡±ç‡∞£‡∞§‡∞≤ ‡∞µ‡∞ø‡∞≤‡±Å‡∞µ‡∞®‡±Å, ‡∞≤‡±ã‡∞™‡∞æ‡∞≤‡±á ‡∞Æ‡∞®‡∞≤‡±ç‡∞®‡∞ø ‡∞Æ‡∞æ‡∞®‡∞µ‡±Å‡∞≤‡±Å‡∞ó‡∞æ ‡∞é‡∞≤‡∞æ ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡±ã ‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞ú‡±á‡∞∏‡±á ‡∞≤‡±ã‡∞§‡±à‡∞® ‡∞ú‡±Ä‡∞µ‡∞ø‡∞§ ‡∞™‡∞æ‡∞†‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞®‡±á‡∞∞‡±ç‡∞™‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞™‡∞∞‡∞ø‡∞™‡±Ç‡∞∞‡±ç‡∞£‡∞§ ‡∞ï‡∞Ç‡∞ü‡±á ‡∞π‡±É‡∞¶‡∞Ø‡∞Ç, ‡∞≠‡∞æ‡∞µ‡±ã‡∞¶‡±ç‡∞µ‡±á‡∞ó‡∞æ‡∞≤‡±Å, ‡∞∏‡∞Ç‡∞ò‡∞∞‡±ç‡∞∑‡∞£, ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞§‡±ã ‡∞ï‡±Ç‡∞°‡∞ø‡∞® ‡∞Ö‡∞∏‡∞Ç‡∞™‡±Ç‡∞∞‡±ç‡∞£‡∞§‡∞≤‡±á ‡∞Æ‡∞®‡∞≤‡±ç‡∞®‡∞ø ‡∞®‡∞ø‡∞ú‡∞Ç‡∞ó‡∞æ ‡∞ï‡∞≤‡±Å‡∞™‡±Å‡∞§‡∞æ‡∞Ø‡∞®‡∞ø, ‡∞Æ‡∞® ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞æ‡∞≤‡∞®‡±Å ‡∞Ö‡∞∞‡±ç‡∞ß‡∞µ‡∞Ç‡∞§‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞Ø‡∞®‡∞ø ‡∞à ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç ‡∞∂‡∞ï‡±ç‡∞§‡∞ø‡∞µ‡∞Ç‡∞§‡∞Ç‡∞ó‡∞æ ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞á‡∞¶‡∞ø ‡∞Ü‡∞∂‡∞®‡±Å ‡∞ï‡∞≤‡∞ø‡∞ó‡∞ø‡∞Ç‡∞ö‡∞ø, ‡∞ú‡±Ä‡∞µ‡∞ø‡∞§‡∞Ç‡∞≤‡±ã‡∞®‡∞ø ‡∞¨‡∞æ‡∞ß‡∞≤‡±Å, ‡∞Ö‡∞Ç‡∞¶‡∞æ‡∞≤‡∞®‡±Å ‡∞∏‡±ç‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø, ‡∞Æ‡∞® ‡∞ö‡±Å‡∞ü‡±ç‡∞ü‡±Ç ‡∞â‡∞®‡±ç‡∞®‡∞µ‡∞æ‡∞∞‡∞ø ‡∞≤‡±ã‡∞™‡∞æ‡∞≤‡∞®‡±Å ‡∞ï‡±Ç‡∞°‡∞æ ‡∞Ö‡∞≠‡∞ø‡∞®‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡±á‡∞∞‡∞£‡∞®‡∞ø‡∞ö‡±ç‡∞ö‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞™‡±ç‡∞∞‡∞§‡∞ø ‡∞í‡∞ï‡±ç‡∞ï‡∞∞‡±Ç ‡∞§‡∞™‡±ç‡∞™‡∞ï ‡∞ö‡±Ç‡∞°‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞ö‡∞ø‡∞§‡±ç‡∞∞‡∞Ç, ‡∞á‡∞¶‡∞ø ‡∞Æ‡∞æ‡∞®‡∞µ‡±Å‡∞°‡∞ø‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡∞ü‡∞Ç‡∞™‡±à ‡∞í‡∞ï ‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞Æ‡±à‡∞® ‡∞™‡∞æ‡∞†‡∞Ç.\n",
        "# Hashtags: #Doraemon #NobitasSkyUtopia #MovieReview #Anime #JapaneseAnimation #LessonLearned #Imperfection #EmbraceYourFlaws #Humanity #Empathy #Love #Connection #HeartOverLogic #SelfAcceptance #GrowthMindset #MeaningfulMovie #MustWatch #DoraemonMovie #Nostalgia #ChildhoodMemories #EmotionalJourney #RealConnections #AppreciateWhatYouHave"
      ],
      "metadata": {
        "id": "22t6pN1YeR4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_chain.get_graph().print_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy2tjuhWvlE7",
        "outputId": "bb327022-51a2-4b25-c000-42e126054c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            +-------------------------------------------+              \n",
            "            | Parallel<translated_review,hashtags>Input |              \n",
            "            +-------------------------------------------+              \n",
            "                       ***                   ***                       \n",
            "                   ****                         ****                   \n",
            "                 **                                 **                 \n",
            "    +----------------+                          +----------------+     \n",
            "    | PromptTemplate |                          | PromptTemplate |     \n",
            "    +----------------+                          +----------------+     \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "+------------------------+                  +------------------------+ \n",
            "| ChatGoogleGenerativeAI |                  | ChatGoogleGenerativeAI | \n",
            "+------------------------+                  +------------------------+ \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "    +-----------------+                         +-----------------+    \n",
            "    | StrOutputParser |                         | StrOutputParser |    \n",
            "    +-----------------+                         +-----------------+    \n",
            "                       ***                   ***                       \n",
            "                          ****           ****                          \n",
            "                              **       **                              \n",
            "            +--------------------------------------------+             \n",
            "            | Parallel<translated_review,hashtags>Output |             \n",
            "            +--------------------------------------------+             \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                          +----------------+                           \n",
            "                          | PromptTemplate |                           \n",
            "                          +----------------+                           \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                      +------------------------+                       \n",
            "                      | ChatGoogleGenerativeAI |                       \n",
            "                      +------------------------+                       \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                          +-----------------+                          \n",
            "                          | StrOutputParser |                          \n",
            "                          +-----------------+                          \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                      +-----------------------+                        \n",
            "                      | StrOutputParserOutput |                        \n",
            "                      +-----------------------+                        \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RAG Introduction**"
      ],
      "metadata": {
        "id": "NQTuqIudOBUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Document Loaders**"
      ],
      "metadata": {
        "id": "UAbugtwJOpLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Document Loader**: In LangChain, a Document Loader is a component that **reads data from a source (like PDFs, websites, or databases) and converts it into a standardized document format that can be processed by the framework**.\n"
      ],
      "metadata": {
        "id": "eutlFoqmlpEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Loader**"
      ],
      "metadata": {
        "id": "AB70zdTIcXOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IQbwNlFzO0nc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01ea09b4-fab7-4052-905d-56cbe2501d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.77)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.31)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\n",
            "google-adk 1.15.1 requires google-genai!=1.37.0,!=1.38.0,!=1.39.0,<=1.40.0,>=1.21.1, but you have google-genai 1.41.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.30 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "10611ebb28f94ec9abf7689f4a4f34f2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "text_loader = TextLoader('/content/Thompson.txt')\n",
        "loaded_doc = text_loader.load()\n",
        "print(loaded_doc)\n",
        "print(type(loaded_doc))\n",
        "print(type(loaded_doc[0]))\n"
      ],
      "metadata": {
        "id": "Bd_kk0tnOc6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PDF loader**"
      ],
      "metadata": {
        "id": "YnoGU8FJchlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "WR_5XLEY3eW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1167f3cf-bee0-4b32-ce95-158b7df97f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdfLoader = PyPDFLoader('/Pravaha_pvt.pdf')\n",
        "loaded_doc = pdfLoader.load()\n",
        "print(len(loaded_doc))\n",
        "print(loaded_doc[4])"
      ],
      "metadata": {
        "id": "K-ANWTQD2PLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CSV loader**"
      ],
      "metadata": {
        "id": "JCLr35zMcnL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "csv_loader = CSVLoader(\"/content/earthquake_alert_balanced_dataset.csv\")\n",
        "loaded_csv = csv_loader.load()\n",
        "print(type(loaded_csv))\n",
        "print(len(loaded_csv))\n",
        "print(loaded_csv[0])"
      ],
      "metadata": {
        "id": "35DenjRzcvzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Web Loader**"
      ],
      "metadata": {
        "id": "GYt-SYTGmf7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "web_loader = WebBaseLoader('https://narasimhakambham.netlify.app/')\n",
        "loaded_web_doc = web_loader.load()\n",
        "print(len(loaded_web_doc))"
      ],
      "metadata": {
        "id": "zbAbsiMfmmPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_web_doc[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9-9DaizbnypP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Directory Loader**"
      ],
      "metadata": {
        "id": "cXTfs5uDozU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
        "\n",
        "# Load TXT files\n",
        "txt_loader = DirectoryLoader(\n",
        "    path=\"/content/ex\",\n",
        "    glob=\"**/*.txt\",\n",
        "    loader_cls=TextLoader,\n",
        "    show_progress=True\n",
        ")\n",
        "txt_docs = txt_loader.load()\n",
        "\n",
        "# Load PDF files\n",
        "pdf_loader = DirectoryLoader(\n",
        "    path=\"/content/ex\",\n",
        "    glob=\"**/*.pdf\",\n",
        "    loader_cls=PyPDFLoader,\n",
        "    show_progress=True\n",
        ")\n",
        "pdf_docs = pdf_loader.load()\n",
        "\n",
        "# Combine documents\n",
        "docs = txt_docs + pdf_docs\n",
        "print(len(docs))\n",
        "print(\"hello\")\n"
      ],
      "metadata": {
        "id": "XM7lF608o3K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternate way of Directory loading\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
        "import glob, os\n",
        "\n",
        "def load_docs(path=\"/content/ex\"):\n",
        "    docs = []\n",
        "    # Get all files recursively\n",
        "    files = glob.glob(os.path.join(path, \"**/*\"), recursive=True)\n",
        "\n",
        "    for f in files:\n",
        "        if os.path.isfile(f):\n",
        "            if f.endswith(\".txt\"):\n",
        "                loader = TextLoader(f)\n",
        "                docs.extend(loader.load())\n",
        "            elif f.endswith(\".pdf\"):\n",
        "                loader = PyPDFLoader(f)\n",
        "                docs.extend(loader.load())\n",
        "            else:\n",
        "                print(f\"Skipping unsupported file type: {f}\")\n",
        "    return docs\n",
        "\n",
        "docs = load_docs()\n",
        "print(f\"Total documents loaded: {len(docs)}\")\n"
      ],
      "metadata": {
        "id": "K57vDLZCsaqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Eager Loading VS Lazy Loading**"
      ],
      "metadata": {
        "id": "x6LiPZDTAN-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdfLoader = PyPDFLoader(\"\"\"/content/Aur√©lien G√©ron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems-O'Reilly Media (2022).pdf\"\"\")\n"
      ],
      "metadata": {
        "id": "zdieoZlFASsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_doc = pdfLoader.load()\n",
        "print(type(loaded_doc))\n",
        "print(len(loaded_doc))\n",
        "print(loaded_doc[40])"
      ],
      "metadata": {
        "id": "HelpCOSLHx0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4017ee2-72f1-49ab-8ca4-f77102127d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "1351\n",
            "page_content='sci-fi and who visit during the weekends. \n",
            "If you use a \n",
            "hierarchical clustering\n",
            "algorithm, it may also subdivide each group into smaller groups. This may\n",
            "help you target your posts for each group.\n",
            "Figure 1-7. \n",
            "An unlabeled training set for unsupervised learning\n",
            "Figure 1-8. \n",
            "Clustering\n",
            "Visualization\n",
            " algorithms are also good examples of unsupervised learning:\n",
            "you feed them a lot of complex and unlabeled data, and they output a 2D or\n",
            "3D representation of your data that can easily be plotted (\n",
            "Figure 1-9\n",
            "). \n",
            "These\n",
            "algorithms try to preserve as much structure as they can (e.g., trying to keep' metadata={'producer': 'calibre 3.48.0 [https://calibre-ebook.com]', 'creator': 'calibre 3.48.0 [https://calibre-ebook.com]', 'creationdate': '2022-12-12T16:42:16+00:00', 'author': 'Aur√©lien G√©ron', 'title': 'Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow', 'source': \"/content/Aur√©lien G√©ron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems-O'Reilly Media (2022).pdf\", 'total_pages': 1351, 'page': 40, 'page_label': '41'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a lazy-loaded PDF generator (does NOT load entire PDF into memory)\n",
        "lazy_loaded_pdf = pdfLoader.lazy_load()\n",
        "print(type(lazy_loaded_pdf)) # <class 'generator'> confirms it's a generator\n",
        "for i, doc in enumerate(lazy_loaded_pdf):\n",
        "  if i == 70 :\n",
        "    print(type(doc))\n",
        "    print(doc)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "JKFrIFOcH02w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c829bd21-dfe6-429d-9865-955db7375950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "<class 'langchain_core.documents.base.Document'>\n",
            "page_content='Underfitting the Training Data\n",
            "As you might guess, \n",
            "underfitting\n",
            " is the opposite of overfitting: it occurs when\n",
            "your model is too simple to learn the underlying structure of the data. For\n",
            "example, a linear model of life satisfaction is prone to underfit; reality is just\n",
            "more complex than the model, so its predictions are bound to be inaccurate,\n",
            "even on the training \n",
            "examples\n",
            ".\n",
            "Here are the main options for fixing this problem:\n",
            "Select a more powerful model, with more parameters.\n",
            "Feed better features to the learning algorithm (feature engineering).\n",
            "Reduce the constraints on the model (for example by reducing the\n",
            "regularization \n",
            "hyperparameter).' metadata={'producer': 'calibre 3.48.0 [https://calibre-ebook.com]', 'creator': 'calibre 3.48.0 [https://calibre-ebook.com]', 'creationdate': '2022-12-12T16:42:16+00:00', 'author': 'Aur√©lien G√©ron', 'title': 'Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow', 'source': \"/content/Aur√©lien G√©ron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems-O'Reilly Media (2022).pdf\", 'total_pages': 1351, 'page': 70, 'page_label': '71'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Chunking/Splitting**"
      ],
      "metadata": {
        "id": "46TwoGciMsog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CharacterTextSplitter"
      ],
      "metadata": {
        "id": "NX5cN2F3S2I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"\"\"I had remarked during my stay in the United States that a democratic state of society, similar to that of the Americans, might offer singular facilities for the establishment of despotism; and I perceived, upon my return to Europe, how much use had already been made, by most of our rulers, of the notions, the sentiments, and the wants created by this same social condition, for the purpose of extending the circle of their power. This led me to think that the nations of Christendom would perhaps eventually undergo some oppression like that which hung over several of the nations of the ancient world.\n",
        "A more accurate examination of the subject, and five years of further meditation, have not diminished my fears, but have changed their object.\n",
        "No sovereign ever lived in former ages so absolute or so powerful as to undertake to administer by his own agency, and without the assistance of intermediate powers, all the parts of a great empire; none ever attempted to subject all his subjects indiscriminately to strict uniformity of regulation and personally to tutor and direct every member of the community. The notion of such an undertaking never occurred to the human mind; and if any man had conceived it, the want of information, the imperfection of the administrative system, and, above all, the natural obstacles caused by the inequality of conditions would speedily have checked the execution of so vast a design.\"\"\""
      ],
      "metadata": {
        "id": "mQSg7PoxZ3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0 , separator ='')"
      ],
      "metadata": {
        "id": "mxliO3TOKaDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = splitter.split_text(text)\n",
        "print(type(result))\n",
        "print(result)\n",
        "print(result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3tPRQlfZ9_J",
        "outputId": "5d9f268b-222d-4f72-9b91-79ab99fa53db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['I had remarked during my stay in the United States', 'that a democratic state of society, similar to th', 'at of the Americans, might offer singular faciliti', 'es for the establishment of despotism; and I perce', 'ived, upon my return to Europe, how much use had a', 'lready been made, by most of our rulers, of the no', 'tions, the sentiments, and the wants created by th', 'is same social condition, for the purpose of exten', 'ding the circle of their power. This led me to thi', 'nk that the nations of Christendom would perhaps e', 'ventually undergo some oppression like that which', 'hung over several of the nations of the ancient wo', 'rld.\\nA more accurate examination of the subject, a', 'nd five years of further meditation, have not dimi', 'nished my fears, but have changed their object.\\nNo', 'sovereign ever lived in former ages so absolute o', 'r so powerful as to undertake to administer by his', 'own agency, and without the assistance of interme', 'diate powers, all the parts of a great empire; non', 'e ever attempted to subject all his subjects indis', 'criminately to strict uniformity of regulation and', 'personally to tutor and direct every member of th', 'e community. The notion of such an undertaking nev', 'er occurred to the human mind; and if any man had', 'conceived it, the want of information, the imperfe', 'ction of the administrative system, and, above all', ', the natural obstacles caused by the inequality o', 'f conditions would speedily have checked the execu', 'tion of so vast a design.']\n",
            "I had remarked during my stay in the United States\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "ywEiDbhUS8iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=50,chunk_overlap=0,separators=['\\n\\n','\\n',' ',''])"
      ],
      "metadata": {
        "id": "OSVM34VlTDHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rec_result = recursive_splitter.split_text(text)\n",
        "print(type(rec_result))\n",
        "print(rec_result)\n",
        "print(rec_result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSTBKEJhTw6y",
        "outputId": "ef096780-fa4b-4b36-90f8-b25fff109155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['I had remarked during my stay in the United States', 'that a democratic state of society, similar to', 'that of the Americans, might offer singular', 'facilities for the establishment of despotism;', 'and I perceived, upon my return to Europe, how', 'much use had already been made, by most of our', 'rulers, of the notions, the sentiments, and the', 'wants created by this same social condition, for', 'the purpose of extending the circle of their', 'power. This led me to think that the nations of', 'Christendom would perhaps eventually undergo some', 'oppression like that which hung over several of', 'the nations of the ancient world.', 'A more accurate examination of the subject, and', 'five years of further meditation, have not', 'diminished my fears, but have changed their', 'object.', 'No sovereign ever lived in former ages so', 'absolute or so powerful as to undertake to', 'administer by his own agency, and without the', 'assistance of intermediate powers, all the parts', 'of a great empire; none ever attempted to subject', 'all his subjects indiscriminately to strict', 'uniformity of regulation and personally to tutor', 'and direct every member of the community. The', 'notion of such an undertaking never occurred to', 'the human mind; and if any man had conceived it,', 'the want of information, the imperfection of the', 'administrative system, and, above all, the', 'natural obstacles caused by the inequality of', 'conditions would speedily have checked the', 'execution of so vast a design.']\n",
            "I had remarked during my stay in the United States\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_sample = \"\"\"\n",
        "def fibonacci(n):\n",
        "    if n <= 0:\n",
        "        return []\n",
        "    elif n == 1:\n",
        "        return [0]\n",
        "    elif n == 2:\n",
        "        return [0, 1]\n",
        "    seq = [0, 1]\n",
        "    for i in range(2, n):\n",
        "        seq.append(seq[-1] + seq[-2])\n",
        "    return seq\n",
        "\n",
        "class Calculator:\n",
        "    def add(self, a, b):\n",
        "        return a + b\n",
        "\n",
        "    def multiply(self, a, b):\n",
        "        return a * b\n",
        "\n",
        "# Main block\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Fibonacci(10):\", fibonacci(10))\n",
        "    calc = Calculator()\n",
        "    print(\"Add:\", calc.add(5, 3))\n",
        "    print(\"Multiply:\", calc.multiply(5, 3))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SY0RsSHkYVod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RecursiveCharacterTextSplitter for codeing languages\n",
        "\n",
        "code_splitter = RecursiveCharacterTextSplitter.from_language(language=\"python\",chunk_size=10,chunk_overlap=0)\n",
        "response_for_code = code_splitter.split_text(code_sample)\n",
        "print(len(response_for_code))\n",
        "print(response_for_code[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yVat9FqTxKA",
        "outputId": "5da17951-aef1-40ea-836b-2a22920c9cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n",
            "['def', 'fibonacci', '(n):', 'if n', '<= 0:', 'return []', 'elif', 'n == 1:', 'return', '[0]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Summary & Next Steps\n",
        "\n",
        "In this notebook, you explored the **foundations of working with LLMs and LangChain using Gemini**:\n",
        "\n",
        "### üîπ You have done:\n",
        "\n",
        "- Called **Gemini** directly using the `google-genai` client  \n",
        "- Used **Groq** through **OpenRouter** with the OpenAI SDK  \n",
        "- Integrated **Gemini with LangChain** via `ChatGoogleGenerativeAI`  \n",
        "- Built prompts using:\n",
        "  - `ChatPromptTemplate`\n",
        "  - `PromptTemplate` with variables and partials  \n",
        "- Parsed model outputs using:\n",
        "  - `StrOutputParser` (plain text)\n",
        "  - `JsonOutputParser`\n",
        "  - `StructuredOutputParser`\n",
        "  - `PydanticOutputParser` + `BaseModel`\n",
        "- Created:\n",
        "  - Simple chains (`prompt | llm`)\n",
        "  - **Sequential chains** (translate ‚Üí summarize)\n",
        "  - **Parallel chains** (translate + hashtags ‚Üí final summary)\n",
        "- Touched **RAG basics**:\n",
        "  - Text splitting (character & recursive)\n",
        "  - Code splitting\n",
        "\n",
        "<br>\n",
        "\n",
        "## üß± What this notebook gives you\n",
        "\n",
        "You now have the core building blocks for:\n",
        "\n",
        "- Building **structured, predictable LLM workflows**\n",
        "- Designing **translation, summarization, and content pipelines**\n",
        "- Moving towards **full RAG systems** and **Agentic AI workflows**\n",
        "\n",
        "This notebook is intentionally designed as a **foundation**.  \n",
        "Next notebooks in the series will go deeper into:\n",
        "\n",
        "- Tools & function calling  \n",
        "- Memory and context management  \n",
        "- Full RAG pipelines (query ‚Üí retrieve ‚Üí synthesize)  \n",
        "- Multi-step **Agentic AI** workflows\n",
        "\n",
        "<br>\n",
        "\n",
        "üí¨ **Tip:**  \n",
        "If you found a section especially useful (e.g., output parsers or chains), copy that part into a separate mini-notebook and adapt it for your own project or domain.\n",
        "\n",
        "**Keep experimenting. This is where real understanding starts. üöÄ**\n"
      ],
      "metadata": {
        "id": "zNWjWVnKhr-a"
      }
    }
  ]
}